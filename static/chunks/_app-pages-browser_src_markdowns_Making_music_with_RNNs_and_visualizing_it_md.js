"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunk_N_E"] = self["webpackChunk_N_E"] || []).push([["_app-pages-browser_src_markdowns_Making_music_with_RNNs_and_visualizing_it_md"],{

/***/ "(app-pages-browser)/./src/markdowns/Making music with RNNs, and visualizing it.md":
/*!*********************************************************************!*\
  !*** ./src/markdowns/Making music with RNNs, and visualizing it.md ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

eval(__webpack_require__.ts("__webpack_require__.r(__webpack_exports__);\n/* harmony default export */ __webpack_exports__[\"default\"] = (\"\\n\\n<p align=\\\"center\\\">\\n<img width= \\\"40%\\\" src=\\\"/images/bachim.png\\\" alt=\\\"ld image\\\">\\n</p>\\nThis post is still work in progress. I'm training a Recurrent neural network on the Bach Chorale dataset in order to get some interesting musical results out of it. I'll share some details on how I trained it, and some early results.\\n\\n#### Introduction\\n\\nRecurrent neural networks (RNNs) applied to music generation are very interesting to me. This is largely because they enable real-time inference, and the memory and optional attention components are intuitive ways of processing information. Maybe it's because they're essential components to our cognition. I'd like to use this project as an ode to these networks.\\n\\nThis post is about generating music, but also on making the technology behind it visible, through artistic visualization. My code for this project is available on github.\\n\\n#### Artistic visualization of RNNs\\nFor this project I'm using the Bach Chorale dataset. The data is freely available online, in one consistent style, and most interestingly, always a 4-part harmony. This allows our network to get tested on generating multiple melodies at once.\\n\\n#### Preprocessing\\nThe data is in a numeric format, with each timestep being one 16th note.\\nFirst all songs are transposed into C major, or A minor scales with the music21 library.\\nAll songs are concatenated into one very long song, with a special character for each end/start of a song.\\n\\n#### Model\\nThe model predicts each 16th timestep one note at a time. Starting with the 1st voice, then the 2nd, 3rd, and 4th. It \\\"snakes\\\" its way through, which is alright to do for LSTMs/GRU's since they've demonstrated to be quite good at counting tasks. The model is implemented in Tensorflow/Keras.\\n\\nDuring training, the network is presented with batches of size 16, each containing a sequence of 128 notes. The notes go roughly through the following layers:\\nembedding(32) -> attention -> GRU1(256) -> GRU2(256) -> Dense(256) -> Dense(num-possible-notes).\\n\\nSome notes on training: It's trained using Adam optimizer, Tensorflow Dataset API, a linear learning rate schedule, and 100 epochs.\\n\\nIt outputs a distribution of which notes are most likely, which is consequently sampled by its distribution. I'm sampling on different 'temperatures' to find the sweet-spot for predictability/chaos.\\n\\nThe last step is converting the notes into an audio signal, MIDI. This is done with python's Mido library. Next to the predicted notes, I'm calculating the entropy for each probability distribution over the notes in the model's output. The entropy is used as \\\"Velocity\\\" signal per note. Normalliy this is used to define loudness in audio software, but you can map it to do many cool things.\\n\\nMidi is imported into Ableton, a digital audio workstation I use, and each midi score is assigned to an instrument.\\n\\nListen to one of the first decent results here. Here's the same midi with entropy and other instrumentation\\n\\n#### visualization\\nBesides midi, the notes are also saved to a JSON file, to use it in the 3D graphics modeling software called Houdini, which is THE state of the art software for procedural graphics.\\n\\nMy friend Alex will make a procedural visualization using the entropy, probability distribtion outputs, predicted notes, and attention layer.\\n\\n#### references\\nmaster thesis on the subject:\\n- BachBot: Automatic composition in the\\nstyle of Bach chorales https://www.mlmi.eng.cam.ac.uk/files/feynman_liang_8224771_assignsubmission_file_liangfeynmanthesis.pdf\\n- music 21 library https://music21.readthedocs.io/en/latest/\\n- vanilla code to start with https://www.tensorflow.org/text/tutorials/text_generation\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///(app-pages-browser)/./src/markdowns/Making music with RNNs, and visualizing it.md\n"));

/***/ })

}]);