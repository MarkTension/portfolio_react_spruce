"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[30],{69030:function(e,t,n){n.r(t),t.default='# On minimizing WGSL / WebGPU texture plumbing\n\nHere\'s a quick and powerful thing I learned during the development of our aritificial life project/paper from my collaborator [Grisha Szep](https://gszep.com/). \n\nBuffers are really powerful, because they\'re easy to read from and write to in any form or size (int32,float32,struct).\n\nSometimes it\'s nice to use storage textures though. [Here\'s](https://webgpufundamentals.org/webgpu/lessons/webgpu-storage-textures.html) a good overview on it. They have built-in performance optimizations (memory layout, texture caching, etc), and when working in 2D, textures are already in the correct domain.\n\nThere\'s some limitations though: A large number of texture formats are available but only certain ones can be used as storage textures.\n\nNot all formats are both READ and WRITEable, The problem is that it\'s only the 1-channel formats that can do both: r32float, r32sint, and r32uint. \n\nSo the choice when doing textures is: \n- you do a bunch of copying of write textures into read textures. \n- Or you do multiple 1-channel storage textures. \n\nBoth introduce a lot of plumbing, which isn\'t nice when actively building something. I want my thinking to be on the algorithmic part, not the plumbing, so in the past I\'d just opt for storageBuffers instead, and convert to texture only when it\'s time to render.\n\n### Texture arrays!\nThe sweet spot to me is using texture arrays. \n\nIn the example below it\'s an array of 10 1-channel textures.\n\n```\n  const storageTextures = device.createTexture({\n    usage: GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.COPY_DST,\n    label: "storageTextures",\n    format: "r32float",\n    size: {\n      width: textures.size.width,\n      height: textures.size.height,\n      depthOrArrayLayers: 10,\n    },\n  });\n\n  const storageTexturesLayout = device.createBindGroupLayout({\n    label: "storageTexturesLayout",\n    entries: [\n      {\n        visibility,\n        binding: 0,\n        storageTexture: {\n          access: "read-write",\n          format: "r32float",\n          viewDimension: "2d-array",\n        },\n      },\n    ]\n  })\n\n  const storageTexturesBindGroup = device.createBindGroup({\n    label: "storageTexturesBindGroup",\n    layout: storageTexturesLayout,\n    entries: [\n      { binding: 0, resource: storageTextures.createView() },\n      ]\n    }\n  )\n```\n\nThen these can be easily read or written to in the shader:\nHere we read e.g. the value of one channel into the second channel.\n\n\n```\n@group(0) @binding(0)  \n  var storageTextures: texture_storage_2d_array<r32float, read_write>;\n\nC_ONE = 0;\nC_TWO = 1;\n\n// reading\nlet c_one = textureLoad(storageTextures, position, C_ONE).r\n\n//writing\ntextureStore(storageTextures, p, C_TWO, c_one);\n```\n\nIt\'s just so convenient to always have the option to use an extra texture without any additional friction.\n\nAnother more real-life example you can find in the specific lightmap implementation [here](https://github.com/webgpu/webgpu-samples/blob/2247bf0e5b095137c2a1b2fac235c94fbb289f28/sample/cornell/radiosity.ts#L59), in the [cornell lightbox](https://webgpu.github.io/webgpu-samples/?sample=cornell)\n\n'}}]);